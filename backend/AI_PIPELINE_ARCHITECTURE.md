# AI Pipeline Architecture - Mini AI Tutor Platform

## ğŸ¯ System Overview

This document describes the complete AI orchestration pipeline using LangChain, LangGraph, MCP Server, and local embeddings - all integrated with the existing Groq LLM API.

---

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Client Application                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Express API Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   RAG    â”‚  â”‚  Agent   â”‚  â”‚  Tools   â”‚  â”‚ Semantic â”‚        â”‚
â”‚  â”‚ Routes   â”‚  â”‚ Routes   â”‚  â”‚ Routes   â”‚  â”‚  Search  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LangGraph Orchestration Layer                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚              AI Workflow Graph (StateGraph)             â”‚     â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”‚     â”‚
â”‚  â”‚  â”‚Input â”‚â†’ â”‚Memory â”‚â†’ â”‚Agent â”‚â†’ â”‚ Tools  â”‚â†’ â”‚Outputâ”‚  â”‚     â”‚
â”‚  â”‚  â”‚ Node â”‚  â”‚ Node  â”‚  â”‚ Node â”‚  â”‚ Node   â”‚  â”‚ Node â”‚  â”‚     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
â”‚  â”‚       â†“         â†“         â†“          â†“          â†“       â”‚     â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚     â”‚
â”‚  â”‚    â”‚     Retry Logic & Error Handling           â”‚      â”‚     â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Service  â”‚   â”‚ MCP Server   â”‚   â”‚ Vector Store â”‚
â”‚   (Groq)     â”‚   â”‚   (Tools)    â”‚   â”‚  (ChromaDB)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Multi-Layer Cache (Redis)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Embedding â”‚ â”‚ Vector   â”‚ â”‚Response  â”‚ â”‚  Tool   â”‚ â”‚
â”‚  â”‚  Cache   â”‚ â”‚  Cache   â”‚ â”‚  Cache   â”‚ â”‚ Cache   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                   â”‚
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Local       â”‚   â”‚  External    â”‚   â”‚   MongoDB    â”‚
â”‚ Embeddings   â”‚   â”‚  Tools       â”‚   â”‚  (Metadata)  â”‚
â”‚ (BGE-small)  â”‚   â”‚ (Files,Web)  â”‚   â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Technology Stack

### Core AI Framework
- **LangChain**: LLM orchestration and chaining
- **LangGraph**: Stateful workflow graphs with cycles
- **LangChain Memory**: Conversation history and context

### Embeddings (100% Free, Local)
- **SentenceTransformers**: Framework for embeddings
- **BGE-small-en-v1.5**: 384-dim, lightweight, high quality
- **GTE-small**: Alternative embedding model
- **all-MiniLM-L6-v2**: Fallback embedding model

### Vector Database
- **ChromaDB**: Primary vector store (local, persistent)
- **FAISS**: Backup option for high-performance search

### MCP (Model Context Protocol)
- **Custom MCP Server**: Tool execution engine
- **Tool Types**: File operations, web scraping, search, code execution

### Caching
- **Redis**: Already integrated for multi-layer caching
- **LRU Cache**: In-memory fallback for embeddings

### Security
- **Zod**: Schema validation
- **DOMPurify**: HTML sanitization
- **Custom**: Prompt injection detection

---

## ğŸ§  Component Architecture

### 1. LangGraph Workflow Engine

```typescript
StateGraph Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input      â”‚ - User query, context
â”‚  Processing â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory     â”‚ - Load conversation history
â”‚  Retrieval  â”‚ - Load user context
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector     â”‚ - Semantic search in knowledge base
â”‚  Search     â”‚ - Retrieve relevant documents
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent      â”‚ - LLM reasoning with Groq API
â”‚  Reasoning  â”‚ - Tool selection
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
    â”Œâ”€â”€â”´â”€â”€â”
    â”‚ ?   â”‚ Need tools?
    â””â”€â”€â”¬â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
   â”‚       â”‚
  Yes     No
   â”‚       â”‚
   â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Tool â”‚ â”‚ Responseâ”‚
â”‚Exec â”‚ â”‚  Output â”‚
â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ (Loop back to Agent)
   â””â”€â”€â”€â”€â”
        â”‚
        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Output  â”‚ - Format response
   â”‚  Node   â”‚ - Save to memory
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Embedding Service Architecture

```javascript
EmbeddingService
â”œâ”€â”€ Model Manager
â”‚   â”œâ”€â”€ BGE-small (primary)
â”‚   â”œâ”€â”€ GTE-small (secondary)
â”‚   â””â”€â”€ MiniLM (fallback)
â”œâ”€â”€ Cache Layer
â”‚   â”œâ”€â”€ Redis (persistent)
â”‚   â””â”€â”€ LRU (in-memory)
â”œâ”€â”€ Batch Processing
â”‚   â”œâ”€â”€ Queue management
â”‚   â””â”€â”€ Parallel processing
â””â”€â”€ Cost Optimization
    â”œâ”€â”€ Deduplication
    â””â”€â”€ Smart batching
```

### 3. Vector Database Schema

```javascript
ChromaDB Collection Schema:
{
  name: "knowledge_base",
  metadata: {
    type: "roadmap" | "conversation" | "flashcard" | "note",
    userId: string,
    courseId: string,
    tags: string[],
    createdAt: timestamp,
    difficulty: "beginner" | "intermediate" | "advanced"
  },
  documents: [text content],
  embeddings: [384-dim vectors],
  ids: [unique identifiers]
}

Indexes:
- Primary: embedding vector (HNSW)
- Secondary: userId, type, tags
- Composite: userId + type
```

### 4. MCP Server Architecture

```javascript
MCP Server Tools:
â”œâ”€â”€ File Operations
â”‚   â”œâ”€â”€ read_file(path)
â”‚   â”œâ”€â”€ write_file(path, content)
â”‚   â”œâ”€â”€ list_files(directory)
â”‚   â””â”€â”€ search_files(pattern)
â”œâ”€â”€ Web Operations
â”‚   â”œâ”€â”€ web_search(query)
â”‚   â”œâ”€â”€ scrape_url(url)
â”‚   â”œâ”€â”€ fetch_api(endpoint)
â”‚   â””â”€â”€ extract_content(html)
â”œâ”€â”€ Code Operations
â”‚   â”œâ”€â”€ execute_code(language, code)
â”‚   â”œâ”€â”€ validate_syntax(code)
â”‚   â””â”€â”€ explain_code(code)
â”œâ”€â”€ Knowledge Operations
â”‚   â”œâ”€â”€ search_knowledge(query)
â”‚   â”œâ”€â”€ store_knowledge(content)
â”‚   â””â”€â”€ update_knowledge(id, content)
â””â”€â”€ Learning Operations
    â”œâ”€â”€ generate_quiz(topic)
    â”œâ”€â”€ explain_concept(concept)
    â””â”€â”€ suggest_resources(topic)
```

### 5. Multi-Layer Caching Strategy

```javascript
Cache Hierarchy:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L1: In-Memory LRU (Hot Data)        â”‚
â”‚ - Recent embeddings (1000 items)    â”‚
â”‚ - Active conversations              â”‚
â”‚ - TTL: 5 minutes                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (miss)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L2: Redis (Warm Data)               â”‚
â”‚ - All embeddings                    â”‚
â”‚ - Vector search results             â”‚
â”‚ - Tool call results                 â”‚
â”‚ - TTL: 24 hours                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (miss)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L3: ChromaDB (Cold Data)            â”‚
â”‚ - Full vector database              â”‚
â”‚ - Persistent storage                â”‚
â”‚ - No expiry                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Security Architecture

### 1. Input Validation Pipeline

```javascript
Request â†’ Zod Schema â†’ Sanitization â†’ Injection Detection â†’ Processing
```

### 2. Prompt Injection Protection

```javascript
Checks:
- System prompt leakage attempts
- Ignore previous instructions
- Role manipulation
- Command injection
- Encoded payloads (base64, hex)
- SQL/NoSQL injection patterns
```

### 3. Tool Sandboxing

```javascript
MCP Tool Execution:
- Whitelist allowed operations
- Path traversal prevention
- Resource limits (CPU, memory, time)
- Output sanitization
- Audit logging
```

### 4. Rate Limiting Strategy

```javascript
Tiers:
- Free: 100 requests/hour, 10 AI calls/hour
- Pro: 1000 requests/hour, 100 AI calls/hour
- Enterprise: Unlimited

Endpoints:
- /api/ai/chat: 50/hour (free), 500/hour (pro)
- /api/ai/embeddings: 100/hour (free), 1000/hour (pro)
- /api/ai/search: 100/hour (free), 1000/hour (pro)
```

---

## ğŸ’° Cost Optimization Strategy

### 1. Embedding Cost Reduction

```javascript
Strategies:
âœ… Use local models (0% cost)
âœ… Cache all embeddings in Redis (99% cache hit)
âœ… Deduplicate identical texts before embedding
âœ… Batch processing (process 100 texts at once)
âœ… Lazy loading (embed only when needed)

Cost Comparison:
- OpenAI Embeddings: $0.0004 per 1K tokens
- Local BGE-small: $0 (only compute cost)
- Savings: 100%
```

### 2. LLM Token Optimization

```javascript
Strategies:
âœ… Cache LLM responses (24-hour TTL)
âœ… Use vector search to reduce context size
âœ… Smart prompt templates (minimal tokens)
âœ… Streaming responses (perceived speed)
âœ… Conversation summarization (reduce history)

Example:
Without optimization: 4000 tokens/request Ã— $0.0001 = $0.0004
With optimization: 800 tokens/request Ã— $0.0001 = $0.00008
Savings: 80%
```

### 3. Vector Search Optimization

```javascript
Strategies:
âœ… Cache search results (1-hour TTL)
âœ… Use approximate search (HNSW) not exact
âœ… Limit result size (top 5 instead of 20)
âœ… Pre-filter with metadata before vector search
âœ… Use smaller embedding dimensions (384 vs 1536)

Performance:
- Query time: 2ms (cached) vs 50ms (uncached)
- Storage: 75% less space (384 vs 1536 dim)
```

---

## ğŸ“ File Structure

```
backend/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ conversationAgent.js      # Chat agent
â”‚   â”‚   â”œâ”€â”€ learningAgent.js          # Educational agent
â”‚   â”‚   â”œâ”€â”€ quizAgent.js              # Quiz generation agent
â”‚   â”‚   â””â”€â”€ roadmapAgent.js           # Roadmap creation agent
â”‚   â”œâ”€â”€ chains/
â”‚   â”‚   â”œâ”€â”€ ragChain.js               # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ summaryChain.js           # Text summarization
â”‚   â”‚   â””â”€â”€ qaChain.js                # Question answering
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ embeddingService.js       # Local embedding service
â”‚   â”‚   â”œâ”€â”€ embeddingCache.js         # Embedding cache layer
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ bgeSmall.js           # BGE-small loader
â”‚   â”‚       â”œâ”€â”€ gteSmall.js           # GTE-small loader
â”‚   â”‚       â””â”€â”€ miniLM.js             # MiniLM loader
â”‚   â”œâ”€â”€ graphs/
â”‚   â”‚   â”œâ”€â”€ chatGraph.js              # LangGraph for chat
â”‚   â”‚   â”œâ”€â”€ ragGraph.js               # LangGraph for RAG
â”‚   â”‚   â””â”€â”€ agentGraph.js             # General agent graph
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ conversationMemory.js     # Chat history
â”‚   â”‚   â”œâ”€â”€ vectorMemory.js           # Semantic memory
â”‚   â”‚   â””â”€â”€ summaryMemory.js          # Summarized history
â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”œâ”€â”€ server.js                 # MCP server
â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”‚   â”œâ”€â”€ fileTools.js          # File operations
â”‚   â”‚   â”‚   â”œâ”€â”€ webTools.js           # Web scraping
â”‚   â”‚   â”‚   â”œâ”€â”€ searchTools.js        # Search tools
â”‚   â”‚   â”‚   â”œâ”€â”€ codeTools.js          # Code execution
â”‚   â”‚   â”‚   â””â”€â”€ knowledgeTools.js     # Knowledge management
â”‚   â”‚   â”œâ”€â”€ validators/
â”‚   â”‚   â”‚   â”œâ”€â”€ toolValidator.js      # Tool input validation
â”‚   â”‚   â”‚   â””â”€â”€ sandboxValidator.js   # Security checks
â”‚   â”‚   â””â”€â”€ executor.js               # Tool execution engine
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ chatPrompts.js            # Chat templates
â”‚   â”‚   â”œâ”€â”€ ragPrompts.js             # RAG templates
â”‚   â”‚   â””â”€â”€ agentPrompts.js           # Agent templates
â”‚   â”œâ”€â”€ security/
â”‚   â”‚   â”œâ”€â”€ inputValidator.js         # Zod schemas
â”‚   â”‚   â”œâ”€â”€ sanitizer.js              # DOMPurify wrapper
â”‚   â”‚   â”œâ”€â”€ injectionDetector.js      # Prompt injection detection
â”‚   â”‚   â””â”€â”€ rateLimiter.js            # AI-specific rate limits
â”‚   â””â”€â”€ vectorstore/
â”‚       â”œâ”€â”€ chromaService.js          # ChromaDB wrapper
â”‚       â”œâ”€â”€ vectorCache.js            # Vector search cache
â”‚       â”œâ”€â”€ ingestion.js              # Document ingestion
â”‚       â””â”€â”€ search.js                 # Semantic search
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ aiController.js               # AI endpoints controller
â”‚   â”œâ”€â”€ ragController.js              # RAG endpoints
â”‚   â””â”€â”€ agentController.js            # Agent endpoints
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ aiRoutes.js                   # AI routes
â”‚   â””â”€â”€ ragRoutes.js                  # RAG routes
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ aiOrchestrator.js             # Main AI orchestration
â”‚   â””â”€â”€ costTracker.js                # Token/cost monitoring
â””â”€â”€ config/
    â””â”€â”€ ai.js                         # AI configuration
```

---

## ğŸ”Œ API Endpoints

### AI Chat & Conversation

```javascript
POST /api/ai/chat
Body: { message, conversationId?, context? }
Response: { response, sources, tokens, cached }

POST /api/ai/stream-chat
Body: { message, conversationId? }
Response: SSE stream of tokens
```

### RAG (Retrieval Augmented Generation)

```javascript
POST /api/ai/rag/search
Body: { query, filters?, limit? }
Response: { results: [{ content, score, metadata }] }

POST /api/ai/rag/ingest
Body: { content, type, metadata }
Response: { success, id, embedded }

POST /api/ai/rag/query
Body: { question, context? }
Response: { answer, sources, confidence }
```

### Agent Operations

```javascript
POST /api/ai/agent/execute
Body: { task, tools?, maxIterations? }
Response: { result, steps, toolCalls, tokens }

GET /api/ai/agent/status/:taskId
Response: { status, progress, intermediate_steps }
```

### Embeddings

```javascript
POST /api/ai/embeddings
Body: { texts: string[] }
Response: { embeddings: number[][], cached, model }

POST /api/ai/embeddings/similarity
Body: { text1, text2 }
Response: { similarity: number, cached }
```

### Knowledge Management

```javascript
POST /api/ai/knowledge/add
Body: { content, metadata, type }
Response: { id, embedded, indexed }

GET /api/ai/knowledge/search
Query: { q, type?, userId?, limit? }
Response: { results, total, cached }

DELETE /api/ai/knowledge/:id
Response: { success, removed }
```

### MCP Tools

```javascript
POST /api/ai/tools/execute
Body: { tool, parameters, validate? }
Response: { result, executionTime, cached }

GET /api/ai/tools/list
Response: { tools: [{ name, description, schema }] }
```

### Monitoring & Analytics

```javascript
GET /api/ai/metrics
Response: {
  tokens: { total, cached, saved },
  embeddings: { total, cached, cost_saved },
  vector_searches: { total, avg_time, cache_hit_ratio },
  tool_calls: { total, by_tool, avg_time }
}

GET /api/ai/cost
Response: {
  llm_cost: number,
  embedding_cost: 0,  // Always 0 (local)
  total_saved: number,
  cache_savings: number
}
```

---

## âš¡ Performance Targets

| Metric | Target | Current |
|--------|--------|---------|
| Embedding Time | <100ms for 1 text | TBD |
| Vector Search | <50ms for top 5 | TBD |
| RAG Query | <500ms total | TBD |
| Cache Hit Ratio | >85% | TBD |
| Token Reduction | >60% | TBD |
| Embedding Cost | $0 (local) | $0 âœ… |

---

## ğŸš€ Implementation Phases

### Phase 1: Foundation (Days 1-2)
- âœ… Install dependencies
- âœ… Set up local embedding service
- âœ… Configure ChromaDB
- âœ… Create base folder structure

### Phase 2: Core AI (Days 3-4)
- âœ… Implement embedding service with cache
- âœ… Build vector store integration
- âœ… Create RAG pipeline
- âœ… Add basic LangChain integration

### Phase 3: LangGraph (Days 5-6)
- âœ… Build state graph for chat
- âœ… Add memory nodes
- âœ… Implement tool executor nodes
- âœ… Add retry/fallback logic

### Phase 4: MCP Server (Days 7-8)
- âœ… Create MCP server
- âœ… Implement tools (file, web, search)
- âœ… Add validation and sandboxing
- âœ… Integrate with LangGraph

### Phase 5: Security & Optimization (Days 9-10)
- âœ… Input validation with Zod
- âœ… Prompt injection detection
- âœ… Multi-layer caching
- âœ… Cost tracking and optimization

### Phase 6: API & Integration (Days 11-12)
- âœ… Create API routes
- âœ… Build controllers
- âœ… Add documentation
- âœ… Integration testing

### Phase 7: Monitoring & Polish (Days 13-14)
- âœ… Add metrics endpoints
- âœ… Cost tracking dashboard
- âœ… Performance optimization
- âœ… Documentation and examples

---

## ğŸ“Š Expected Outcomes

### Performance
- **90% cache hit ratio** for embeddings
- **80% cache hit ratio** for vector searches
- **60% token reduction** with RAG
- **Sub-second response times** for cached queries

### Cost Savings
- **100% embedding cost saved** (vs OpenAI: $500/month â†’ $0)
- **80% token cost saved** (vs full context: $300/month â†’ $60/month)
- **Total savings**: ~$740/month at scale

### User Experience
- Real-time streaming responses
- Contextual, accurate answers
- Personalized learning paths
- Intelligent tool usage

### Developer Experience
- Clean, modular architecture
- Easy to extend with new tools
- Comprehensive documentation
- Type-safe with validation

---

## ğŸ”— Integration with Existing Systems

### 1. Groq LLM Service
```javascript
// Already integrated in services/groqService.js
import { groqService } from './services/groqService.js';

// Use in LangChain
const llm = new ChatGroq({
  groqApiKey: process.env.GROQ_API_KEY,
  modelName: process.env.GROQ_MODEL,
  streaming: true
});
```

### 2. Redis Cache
```javascript
// Already integrated for caching
import cacheManager from './utils/CacheManager.js';

// Use for embedding cache, vector cache, response cache
await cacheManager.set('embedding:hash', vector, 86400);
```

### 3. MongoDB
```javascript
// Store metadata, user context, conversation history
import Conversation from './models/Conversation.js';
import Roadmap from './models/Roadmap.js';

// Retrieve for context in RAG
const userContext = await User.findById(userId).select('learningGoals');
```

---

## ğŸ“– Usage Examples

### Example 1: RAG Query

```javascript
const result = await ragQuery({
  question: "Explain recursion in Python",
  userId: "user123",
  context: { skill_level: "beginner" }
});

// Returns:
{
  answer: "Recursion is when a function calls itself...",
  sources: [
    { content: "...", score: 0.92, metadata: {...} }
  ],
  tokens: 450,
  cached: false
}
```

### Example 2: Agent with Tools

```javascript
const result = await agentExecute({
  task: "Create a Python quiz on loops",
  tools: ['generate_quiz', 'search_knowledge'],
  maxIterations: 5
});

// Agent automatically:
// 1. Searches knowledge base for loop examples
// 2. Generates quiz questions
// 3. Validates questions
// 4. Returns formatted quiz
```

### Example 3: Semantic Search

```javascript
const results = await vectorSearch({
  query: "How to optimize React performance",
  filters: { type: "roadmap", difficulty: "intermediate" },
  limit: 5
});

// Returns top 5 most relevant roadmaps with similarity scores
```

---

## ğŸ¯ Success Metrics

- âœ… 100% free embeddings (no API costs)
- âœ… <100ms embedding time
- âœ… >85% cache hit ratio
- âœ… 60% token reduction via RAG
- âœ… Sub-second query responses
- âœ… Secure tool execution
- âœ… Production-ready architecture

---

## ğŸ“š Next Steps

1. Review and approve architecture
2. Install dependencies
3. Begin Phase 1 implementation
4. Iterate based on testing

This architecture provides a production-ready, cost-optimized AI pipeline for your Mini AI Tutor platform! ğŸš€
